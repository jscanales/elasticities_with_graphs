{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulations import Simulation, StructuralModel, ModelInputParams, IVOptions, ModelResults, ModelMetrics\n",
    "from estimation import ar_model_fit, ar_model_analysis\n",
    "from plot_tools import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.axes import Axes\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.legend_handler import HandlerPatch\n",
    "from matplotlib.patches import Rectangle, FancyArrowPatch, Patch, FancyArrow\n",
    "import mpl_toolkits.axisartist as axisartist\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import random\n",
    "from typing import Literal\n",
    "\n",
    "from statsmodels.stats import proportion\n",
    "import statsmodels.stats.weightstats as ws\n",
    "\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER:str = \"results/\"\n",
    "\n",
    "def write_results_to_file(file_path: str, results_df: pd.DataFrame):\n",
    "    results_df.to_csv(FOLDER+file_path+'.csv')\n",
    "\n",
    "def read_results_from_file(file_path: str, header_lines:int=2) -> pd.DataFrame:\n",
    "    return pd.read_csv(FOLDER+file_path, header=[i for i in range(header_lines)], index_col=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAGs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NODE_POSITIONS = {\n",
    "    \"$W_{t-3}$\": (-3, 5), \"$W_{t-2}$\": (0, 5), \"$W_{t-1}$\": (3, 5), \"$W_t$\": (6, 5), \"$W_{t+1}$\": (9, 5),\n",
    "    \"$P_{t-3}$\": (-3, 3), \"$P_{t-2}$\": (0, 3), \"$P_{t-1}$\": (3, 3), \"$P_t$\": (6, 3), \"$P_{t+1}$\": (9, 3),\n",
    "    \"$D_{t-3}$\": (-3, 0), \"$D_{t-2}$\": (0, 0), \"$D_{t-1}$\": (3, 0), \"$D_t$\": (6, 0), \"$D_{t+1}$\": (9, 0),\n",
    "    }\n",
    "\n",
    "ARROW_SIZE = 15\n",
    "\n",
    "DAG_LINE_WIDTH = 1.5\n",
    "DAG_XLIM = (-1.5, 7.5)\n",
    "\n",
    "def get_base_dag():\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    G.add_node(\"$W_{t+1}$\")\n",
    "    G.add_node(\"$W_t$\")\n",
    "    G.add_node(\"$W_{t-1}$\")\n",
    "    G.add_node(\"$W_{t-2}$\")\n",
    "\n",
    "    G.add_node(\"$P_{t+1}$\")\n",
    "    G.add_node(\"$P_t$\")\n",
    "    G.add_node(\"$P_{t-1}$\")\n",
    "    G.add_node(\"$P_{t-2}$\")\n",
    "\n",
    "    G.add_node(\"$D_{t+1}$\")\n",
    "    G.add_node(\"$D_t$\")\n",
    "    G.add_node(\"$D_{t-1}$\")\n",
    "    G.add_node(\"$D_{t-2}$\")\n",
    "\n",
    "    return G\n",
    "\n",
    "def add_wind_edges(G:nx.DiGraph, weight:float, color_t_1:str, ar:bool=True):\n",
    "    if ar:\n",
    "        G.add_edge(\"$W_{t-3}$\", \"$W_{t-2}$\", color=\"k\", weight=weight, style=\"dashed\")\n",
    "        G.add_edge(\"$W_{t-2}$\", \"$W_{t-1}$\", color=\"k\", weight=weight)\n",
    "        G.add_edge(\"$W_{t-1}$\", \"$W_t$\", color=color_t_1, weight=weight)\n",
    "        G.add_edge(\"$W_t$\", \"$W_{t+1}$\", color=\"k\", weight=weight, style=\"dashed\")\n",
    "\n",
    "    G.add_edge(\"$W_{t-3}$\", \"$P_{t-3}$\", color=\"k\", weight=weight)\n",
    "    G.add_edge(\"$W_{t-2}$\", \"$P_{t-2}$\", color=\"k\", weight=weight)\n",
    "    G.add_edge(\"$W_{t-1}$\", \"$P_{t-1}$\", color=color_t_1, weight=weight)\n",
    "    G.add_edge(\"$W_t$\", \"$P_t$\", color=\"k\", weight=weight)\n",
    "    G.add_edge(\"$W_{t+1}$\", \"$P_{t+1}$\", color=\"k\", weight=weight)\n",
    "\n",
    "def add_elasticity_edges(G:nx.DiGraph, weight:float, color_t_1:str):\n",
    "    G.add_edge(\"$P_{t-3}$\", \"$D_{t-3}$\", color=\"k\", weight=weight)\n",
    "    G.add_edge(\"$P_{t-2}$\", \"$D_{t-2}$\", color=\"k\", weight=weight)\n",
    "    G.add_edge(\"$P_{t-1}$\", \"$D_{t-1}$\", color=color_t_1, weight=weight)\n",
    "    G.add_edge(\"$P_t$\", \"$D_t$\", color=\"red\", weight=weight)\n",
    "    G.add_edge(\"$P_{t+1}$\", \"$D_{t+1}$\", color=\"k\", weight=weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_equilibrium_edges_to_DAG(axes:Axes, node_positions:dict):\n",
    "    new_edges = [\n",
    "        (\"$D_t$\", \"$P_t$\", \"k\"),\n",
    "        (\"$D_{t-1}$\", \"$P_{t-1}$\", \"k\"),\n",
    "        (\"$D_{t-2}$\", \"$P_{t-2}$\", \"k\"),\n",
    "    ]\n",
    "\n",
    "    node_size = 0.85\n",
    "    for edge in new_edges:\n",
    "        source, target, color = edge\n",
    "        rad = -0.4\n",
    "        # Calculate the offset based on node size\n",
    "        offset = 0.5 * node_size  # Adjust this factor as needed\n",
    "        # Adjust source and target coordinates based on node size\n",
    "        source_x, source_y = node_positions[source]\n",
    "        target_x, target_y = node_positions[target]\n",
    "        dx = target_x - source_x\n",
    "        dy = target_y - source_y\n",
    "        length = (dx ** 2 + dy ** 2) ** 0.5\n",
    "        if length != 0:\n",
    "            dx /= length\n",
    "            dy /= length\n",
    "        source_x += offset / 10 \n",
    "        source_y += dy * offset \n",
    "        target_x += offset / 10 \n",
    "        target_y += - dy * offset \n",
    "\n",
    "        # Draw the arrow with adjusted coordinates\n",
    "        arrowprops=dict(arrowstyle=\"<|-|>\",\n",
    "                        mutation_scale=ARROW_SIZE,\n",
    "                        color=color,\n",
    "                        connectionstyle=f\"arc3,rad={rad}\",\n",
    "                        linestyle='-',\n",
    "                        lw=DAG_LINE_WIDTH,\n",
    "                        alpha=1)\n",
    "        axes.annotate(\"\",\n",
    "                    xy=(source_x, source_y),\n",
    "                    xytext=(target_x, target_y),\n",
    "                    arrowprops=arrowprops\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model I: inertial demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dag_model_I_on_axes(axes:Axes, demand_ar:bool=True, elasticity:bool=True, wind_ar:bool=True, color_open:str=\"dodgerblue\"):\n",
    "\n",
    "    # Create a Directed Graph (DAG)\n",
    "    G = get_base_dag()\n",
    "\n",
    "    # Add nodes\n",
    "    add_wind_edges(G, DAG_LINE_WIDTH, color_open, wind_ar)\n",
    "\n",
    "    if elasticity:\n",
    "        add_elasticity_edges(G, DAG_LINE_WIDTH, color_open)\n",
    "    \n",
    "\n",
    "    weight=DAG_LINE_WIDTH\n",
    "    \n",
    "    if demand_ar:\n",
    "\n",
    "        G.add_edge(\"$D_{t-3}$\", \"$D_{t-2}$\", color=\"k\", weight=weight, style=\"dashed\")\n",
    "        G.add_edge(\"$D_{t-2}$\", \"$D_{t-1}$\",color=\"k\", weight=weight)\n",
    "        G.add_edge(\"$D_{t-1}$\", \"$D_t$\", color=color_open, weight=weight)\n",
    "        G.add_edge(\"$D_t$\", \"$D_{t+1}$\", color=\"k\", weight=weight, style=\"dashed\")\n",
    "\n",
    "        G.add_edge(\"$D_{t-3}$\", \"$P_{t-2}$\", color=\"k\", weight=weight, style=\"dashed\")\n",
    "        G.add_edge(\"$D_{t-2}$\", \"$P_{t-1}$\", color=\"k\", weight=weight)\n",
    "        G.add_edge(\"$D_{t-1}$\", \"$P_t$\", color=\"k\", weight=weight)\n",
    "        G.add_edge(\"$D_t$\", \"$P_{t+1}$\", color=\"k\", weight=weight, style=\"dashed\")\n",
    "\n",
    "\n",
    "    edges = G.edges()\n",
    "    colors = [G[u][v]['color'] for u,v in edges]\n",
    "    weights = [G[u][v]['weight'] for u,v in edges]\n",
    "    styles = [G[u][v].get('style', '-') for u,v in edges]\n",
    "    connection_styles = [G[u][v].get('connectionstyle', \"arc3\") for u, v in edges]\n",
    "\n",
    "    # Draw the graph with specific node positions\n",
    "    nx.draw(G, pos=NODE_POSITIONS, node_color='white', with_labels=True, labels={node: node for node in G.nodes()}, \n",
    "            font_color='black', node_size=800, font_size=10, edge_color=colors, width=weights, ax=axes, style=styles, \n",
    "            connectionstyle=connection_styles, arrowsize=ARROW_SIZE, edgecolors='black')\n",
    "    \n",
    "    add_equilibrium_edges_to_DAG(axes, NODE_POSITIONS)\n",
    "\n",
    "    axes.set_aspect('equal', adjustable='box')\n",
    "\n",
    "\n",
    "    axes.set_xlim(DAG_XLIM)\n",
    "    axes.set_ylim(-1.75, 6.25)\n",
    "    axes.set_xlabel(\"Demand response to prices propagates through time\", fontsize=\"large\")\n",
    "    axes.set_title(\"Model I: Inertial Demand\", fontsize=\"large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_I():\n",
    "    fig, axs = plt.subplots(1, 1, sharex=False,  sharey=False, figsize=(REGULAR_WIDTH, HEIGHT))\n",
    "    plot_dag_model_I_on_axes(axs)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_I()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model I (Figure 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def figure_3():\n",
    "    fig, axs = plt.subplots(1, 1, sharex=False,  sharey=False, figsize=(REGULAR_WIDTH, HEIGHT))\n",
    "    plot_dag_model_I_on_axes(axs)\n",
    "\n",
    "    fig.tight_layout(pad=2)\n",
    "\n",
    "\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "    save_figure(fig=fig, figname=\"figure_2_main_model\")\n",
    "\n",
    "figure_3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variants (Figure 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def figure_4():\n",
    "    fig, axs = plt.subplots(1, 3, sharex=False,  sharey=False, figsize=(EXTRA_WIDTH, HEIGHT))\n",
    "    plot_dag_model_I_on_axes(axs[0], wind_ar=False, color_open=\"k\")\n",
    "    plot_dag_model_I_on_axes(axs[1], demand_ar=False, color_open=\"k\")\n",
    "    plot_dag_model_I_on_axes(axs[2], elasticity=False, color_open=\"k\")\n",
    "    axs[0].set_title(\"a) I.i.d. instrument ($\\\\beta^W = 0$)\")\n",
    "    axs[1].set_title(\"b) No dir. str. autocor ($\\\\beta^{D1} = 0$)\")\n",
    "    axs[2].set_title(\"c) No price response ($\\\\beta^P = 0$)\")\n",
    "    fig.show()\n",
    "\n",
    "    save_figure(fig=fig, figname=\"figure_4_variant_DAGs\")\n",
    "\n",
    "\n",
    "figure_4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model II: heterogeneous demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_marginalized_demand(axes:Axes, node_positions:dict, xlim:tuple[float, float]):\n",
    "\n",
    "    new_edges = [\n",
    "        (\"$D_{t-3}$\", \"$D_{t-2}$\", \"k\", \"--\"),\n",
    "        (\"$D_{t-2}$\", \"$D_{t-1}$\", \"k\", \"-\"),\n",
    "        (\"$D_{t-1}$\", \"$D_t$\", \"darkorange\", \"-\"),\n",
    "        (\"$D_t$\", \"$D_{t+1}$\", \"k\", \"--\"),\n",
    "    ]\n",
    "\n",
    "    node_size = 0.85\n",
    "    for i, edge in enumerate(new_edges):\n",
    "        source, target, color, style = edge\n",
    "        rad = -0.4\n",
    "        # Calculate the offset based on node size\n",
    "        offset = 0.5 * node_size  # Adjust this factor as needed\n",
    "        # Adjust source and target coordinates based on node size\n",
    "        source_x, source_y = node_positions[source]\n",
    "        target_x, target_y = node_positions[target]\n",
    "\n",
    "        source_x += offset / 10\n",
    "        source_y += - offset\n",
    "        target_x += - offset / 10\n",
    "        target_y += - offset\n",
    "\n",
    "\n",
    "        arrowstyle = \"<|-|>\"\n",
    "        \n",
    "        # Draw the arrow with adjusted coordinates\n",
    "        arrowprops=dict(arrowstyle=arrowstyle,\n",
    "                        mutation_scale=ARROW_SIZE,\n",
    "                        color=color,\n",
    "                        connectionstyle=f\"arc3,rad={rad}\" if i != 0 else f\"arc3,rad={-rad}\",\n",
    "                        linestyle=style,\n",
    "                        lw=DAG_LINE_WIDTH,\n",
    "                        alpha=1)\n",
    "        if i == 0:\n",
    "            ann = axes.annotate(\"\",\n",
    "                    xytext=(source_x, source_y),\n",
    "                    xy=(target_x, target_y),\n",
    "                    arrowprops=arrowprops,\n",
    "                    annotation_clip=False,\n",
    "                    clip_on=True,\n",
    "                )\n",
    "        else:\n",
    "            ann = axes.annotate(\"\",\n",
    "                        xy=(source_x, source_y),\n",
    "                        xytext=(target_x, target_y),\n",
    "                        arrowprops=arrowprops,\n",
    "                        annotation_clip=False,\n",
    "                        clip_on=True,\n",
    "                    )\n",
    "            \n",
    "        if ann.arrow_patch is not None:\n",
    "            ann.arrow_patch.set_clip_box(axes.bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dag_model_II_on_axes(axes:Axes):\n",
    "    # Create a Directed Graph (DAG)\n",
    "    G = get_base_dag()\n",
    "    \n",
    "    add_wind_edges(G, DAG_LINE_WIDTH, \"darkorange\")\n",
    "    add_elasticity_edges(G, DAG_LINE_WIDTH, \"darkorange\")\n",
    "\n",
    "    weight=DAG_LINE_WIDTH\n",
    "\n",
    "    # Add edges\n",
    "    edges = G.edges()\n",
    "    colors = [G[u][v]['color'] for u,v in edges]\n",
    "    weights = [G[u][v]['weight'] for u,v in edges]\n",
    "    styles = [G[u][v].get('style', '-') for u,v in edges]\n",
    "    connection_styles = [G[u][v].get('connectionstyle', \"arc3\") for u, v in edges]\n",
    "    print(connection_styles)\n",
    "\n",
    "    # Draw the graph with specific node positions\n",
    "    nx.draw(G, pos=NODE_POSITIONS, node_color='white', with_labels=True, labels={node: node for node in G.nodes()}, \n",
    "            font_color='black', node_size=800, font_size=10, edge_color=colors, width=weights, ax=axes, style=styles, \n",
    "            connectionstyle=connection_styles, arrowsize=ARROW_SIZE, edgecolors='black')\n",
    "\n",
    "    add_equilibrium_edges_to_DAG(axes, NODE_POSITIONS)\n",
    "    add_marginalized_demand(axes, NODE_POSITIONS, (-0.3, 2.3))\n",
    "\n",
    "\n",
    "    axes.set_aspect('equal', adjustable='box')\n",
    "        \n",
    "    axes.set_xlim(DAG_XLIM)\n",
    "    axes.set_ylim(-1.75, 6.25)\n",
    "    axes.set_title(\"Model II: Partially responsive demand\", fontsize=\"large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_II():\n",
    "    fig, axs = plt.subplots(1, 1, sharex=False,  sharey=False, figsize=(REGULAR_WIDTH, HEIGHT))\n",
    "    plot_dag_model_II_on_axes(axs)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_II()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model III: cross-price elasticity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_cross_price_elasticity_edges(G:nx.DiGraph, weight:float, color_t_1:str):\n",
    "    G.add_edge(\"$P_{t-3}$\", \"$D_{t-2}$\", color=\"k\", weight=weight, style=\"dashed\")\n",
    "    G.add_edge(\"$P_{t-2}$\", \"$D_{t-1}$\", color=\"k\", weight=weight)\n",
    "    G.add_edge(\"$P_{t-1}$\", \"$D_t$\", color=color_t_1, weight=weight)\n",
    "    G.add_edge(\"$P_t$\", \"$D_{t+1}$\", color=\"k\", weight=weight, style=\"dashed\")\n",
    "\n",
    "    G.add_edge(\"$P_{t-3}$\", \"$P_{t-2}$\", color=\"k\", weight=weight, style=\"dashed\")\n",
    "    G.add_edge(\"$P_{t-2}$\", \"$P_{t-1}$\", color=\"k\", weight=weight)\n",
    "    G.add_edge(\"$P_{t-1}$\", \"$P_t$\", color=\"k\", weight=weight)\n",
    "    G.add_edge(\"$P_t$\", \"$P_{t+1}$\", color=\"k\", weight=weight, style=\"dashed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dag_model_III_on_axes(axes:Axes):\n",
    "    # Create a Directed Graph (DAG)\n",
    "    G = get_base_dag()\n",
    "    \n",
    "    add_wind_edges(G, DAG_LINE_WIDTH, \"dodgerblue\")\n",
    "    add_elasticity_edges(G, DAG_LINE_WIDTH, \"k\")\n",
    "    add_cross_price_elasticity_edges(G, DAG_LINE_WIDTH, \"dodgerblue\")\n",
    "\n",
    "    weight=DAG_LINE_WIDTH\n",
    "\n",
    "    # Add edges\n",
    "\n",
    "    edges = G.edges()\n",
    "    colors = [G[u][v]['color'] for u,v in edges]\n",
    "    weights = [G[u][v]['weight'] for u,v in edges]\n",
    "    styles = [G[u][v].get('style', '-') for u,v in edges]\n",
    "    connection_styles = [G[u][v].get('connectionstyle', \"arc3\") for u, v in edges]\n",
    "    print(connection_styles)\n",
    "\n",
    "    \n",
    "    # Draw the graph with specific node positions\n",
    "    nx.draw(G, pos=NODE_POSITIONS, node_color='white', with_labels=True, labels={node: node for node in G.nodes()}, \n",
    "            font_color='black', node_size=800, font_size=10, edge_color=colors, width=weights, ax=axes, style=styles, \n",
    "            connectionstyle=connection_styles, arrowsize=ARROW_SIZE, edgecolors='black')\n",
    "\n",
    "    add_equilibrium_edges_to_DAG(axes, NODE_POSITIONS)\n",
    "\n",
    "    axes.set_aspect('equal', adjustable='box')\n",
    "        \n",
    "\n",
    "    axes.set_xlim(DAG_XLIM)\n",
    "    axes.set_ylim(-1.75, 6.25)\n",
    "    axes.set_title(\"Model III: Demand shifting\", fontsize=\"large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_III():\n",
    "    fig, axs = plt.subplots(1, 1, sharex=False,  sharey=False, figsize=(REGULAR_WIDTH, HEIGHT))\n",
    "    plot_dag_model_III_on_axes(axs)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_III()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model II and III (Figure 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def figure_3():\n",
    "    fig, axs = plt.subplots(1, 2, sharex=False,  sharey=False, figsize=(WIDE_WIDTH, HEIGHT))\n",
    "    plot_dag_model_II_on_axes(axs[0])\n",
    "    plot_dag_model_III_on_axes(axs[1])\n",
    "\n",
    "    fig.tight_layout(pad=2)\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "    save_figure(fig=fig, figname=\"figure_3_alternative_models\")\n",
    "\n",
    "figure_3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Punchline (Figure 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation_by_demand_arg(\n",
    "    sample: int = 8760,\n",
    "    runs: int = 10,\n",
    "    linspace: int = 21,\n",
    "    model:StructuralModel = StructuralModel.Model_I,\n",
    "    estimators:list[ModelInputParams]=MODELS,\n",
    "    wind_manual_ar_sum: float | None = None,\n",
    "    ) -> pd.DataFrame:\n",
    "    \n",
    "    # Create the X axis\n",
    "    \n",
    "    xx = np.linspace(-200, 200, linspace)\n",
    "    dd = np.linspace(-0.249, 0.999, linspace)\n",
    "\n",
    "    # Create the empty lists to store the analysis output\n",
    "\n",
    "    output_lists:dict[str, dict[str, list]] = {}\n",
    "    for estimator in estimators:\n",
    "        output_lists[estimator.name] = {\"Mean\":[],\n",
    "                                        \"Upper\":[],\n",
    "                                        \"Lower\":[]}\n",
    "\n",
    "\n",
    "    for i, x in enumerate(xx):\n",
    "        d = dd[i]\n",
    "\n",
    "        simulation = Simulation(sample=sample)\n",
    "\n",
    "        simulation.run_simulations_by_model(\n",
    "            runs=runs,\n",
    "            estimators=estimators,\n",
    "            model=model,\n",
    "            demand_arg=x if model == StructuralModel.Model_III else d,\n",
    "            simulation_count=i,\n",
    "            wind_manual_ar_sum=wind_manual_ar_sum\n",
    "        )\n",
    "\n",
    "        for estimator in estimators:\n",
    "\n",
    "            try:\n",
    "\n",
    "                output_lists[estimator.name][\"Mean\"].append(simulation.models[estimator.name].mean)\n",
    "                output_lists[estimator.name][\"Upper\"].append(np.percentile(simulation.models[estimator.name].estimates, 95))\n",
    "                output_lists[estimator.name][\"Lower\"].append(np.percentile(simulation.models[estimator.name].estimates, 5))\n",
    "\n",
    "            except KeyError as e:\n",
    "                \n",
    "                output_lists[estimator.name][\"Mean\"].append(simulation.models[estimator.name+\"_P0\"].mean)\n",
    "                output_lists[estimator.name][\"Upper\"].append(np.percentile(simulation.models[estimator.name+\"_P0\"].estimates, 95))\n",
    "                output_lists[estimator.name][\"Lower\"].append(np.percentile(simulation.models[estimator.name+\"_P0\"].estimates, 5))\n",
    "\n",
    "    # Organize results into a DataFrame\n",
    "\n",
    "    sub_index = [\"Mean\", \"Upper\", \"Lower\"]\n",
    "    index = pd.MultiIndex.from_product([[estimator.name for estimator in estimators], sub_index])\n",
    "    \n",
    "    columns = xx.tolist() if model in [StructuralModel.Model_III, StructuralModel.Model_IV] else dd.tolist()\n",
    "\n",
    "    print(model, columns)\n",
    "\n",
    "    data = []\n",
    "    for estimator, dictionary in output_lists.items():\n",
    "        data.extend([dictionary[\"Mean\"], dictionary[\"Upper\"], dictionary[\"Lower\"]])\n",
    "\n",
    "    results_df = pd.DataFrame(data, index=index, columns=columns).T\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_punchline(file_path:str, estimators:list[ModelInputParams], sample:int, runs:int, linspace:int, model:StructuralModel) -> pd.DataFrame:\n",
    "    try:\n",
    "        df = read_results_from_file(file_path+'.csv')\n",
    "\n",
    "        missing_estimators = []\n",
    "        for estimator in estimators:\n",
    "            if not estimator.name in df.columns.get_level_values(0):\n",
    "                missing_estimators.append(estimator)\n",
    "                print(estimator.name+\" is missing for \"+file_path)\n",
    "\n",
    "        if missing_estimators: \n",
    "            df_b = run_simulation_by_demand_arg(sample=sample, runs=runs, linspace=linspace, estimators=missing_estimators, model=model)\n",
    "            df = df.join(df_b)\n",
    "            print(df.columns)\n",
    "\n",
    "            write_results_to_file(file_path, df)\n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        df = run_simulation_by_demand_arg(sample=sample, runs=runs, linspace=linspace, estimators=estimators, model=model)\n",
    "        write_results_to_file(file_path, df)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_punchline_panel(axes:Axes, df:pd.DataFrame, color_estimator_dict:dict[str, ModelInputParams], xlim:tuple[float, float], xlabel:str, model_name:str, ylabel:str, add_label:bool):\n",
    "    x_axis = df.index\n",
    "\n",
    "    llss = ['-', '--', ':', '-.']\n",
    "\n",
    "    model_labels = [\"Naive IV: \", \"Conditional IV: \", \"Nuisance IV: \"]\n",
    "\n",
    "\n",
    "    for i, (color, estimator) in enumerate(color_estimator_dict.items()):\n",
    "\n",
    "        axes.plot(x_axis, df[estimator.name]['Mean'], color=color, label=model_labels[i]+estimator.latex_name if add_label else \"\", ls=llss[i])\n",
    "        axes.fill_between(x_axis, df[estimator.name]['Upper'], df[estimator.name]['Lower'], color=color, alpha=0.3)\n",
    "\n",
    "    axes.axhline(0, xlim[0], max(1, xlim[1]), color='black', linewidth=0.8)\n",
    "    axes.axvline(0, -500, 100, color='black', linewidth=0.8)\n",
    "    axes.set_xlim(xlim)\n",
    "\n",
    "    axes.set_xlabel(xlabel, size=\"large\")\n",
    "    axes.set_ylabel(ylabel=ylabel, size=\"large\")\n",
    "    # axes.set_title(model_name, size=\"large\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def punchline_plot_legend(estimators:list[ModelInputParams]):\n",
    "    # Plot lines\n",
    "    dodgerblue_line = Line2D([0, 1], [0, 1], color='dodgerblue', label=estimators[0].latex_name, ls=\"-\")\n",
    "    darkorange_line = Line2D([0, 1], [0, 0.5], color='darkorange', label=estimators[1].latex_name, ls=\"--\")\n",
    "    darkgreen_line = Line2D([0, 1], [0, 0.2], color='darkgreen', label=estimators[2].latex_name, ls=\":\")\n",
    "\n",
    "    # Create arrows\n",
    "    red_arrow = FancyArrowPatch((0.1, 0.9), (0.3, 0.7), color='red', arrowstyle='-|>', linewidth=2, mutation_scale=15, label='effect of interest ($\\\\beta^P=-100$)')\n",
    "    blue_arrow = FancyArrowPatch((0.2, 0.6), (0.4, 0.4), color='dodgerblue', arrowstyle='-|>', linewidth=2, mutation_scale=15, label='unblocked path given $\\\\emptyset$')\n",
    "    orange_arrow = FancyArrowPatch((0.3, 0.3), (0.5, 0.1), color='darkorange', arrowstyle='-|>', linewidth=2, mutation_scale=15, label='blocked path given $\\\\emptyset$')\n",
    "\n",
    "    # Create custom legend\n",
    "    legend_elements = [\n",
    "        blue_arrow,\n",
    "        orange_arrow,\n",
    "        red_arrow,\n",
    "        dodgerblue_line,\n",
    "        darkorange_line,\n",
    "        darkgreen_line\n",
    "    ]\n",
    "\n",
    "    return legend_elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def punchline_plot(runs=10, linspace=21, sample=8760, color_estimator_dict:dict[str, ModelInputParams]={\n",
    "    \"dodgerblue\":ModelInputParams(IVOptions.REGULAR, 0),\n",
    "    \"darkorange\":ModelInputParams(IVOptions.CONDITIONAL_WIND, 26),\n",
    "    \"darkred\":ModelInputParams(IVOptions.CONDITIONAL_DEMAND, 1),\n",
    "    \"darkgreen\":ModelInputParams(IVOptions.NUISANCE_ORDER, 1),\n",
    "    \"pink\":ModelInputParams(IVOptions.TRUNCATED_NUISANCE_ORDER, order=26, order_d=1),\n",
    "    \"brown\":ModelInputParams(IVOptions.CLEAN_2dim_ORDER, order=26, order_price=1),\n",
    "}, file:str=\"\", \n",
    "models:list[StructuralModel] = [StructuralModel.Model_I, \n",
    "                                StructuralModel.Model_II,\n",
    "                                ]\n",
    "):\n",
    "\n",
    "    name_dict = {\n",
    "        StructuralModel.Model_I:\"simple_model\",\n",
    "        StructuralModel.Model_II:\"autocorrelated_error\",\n",
    "        # StructuralModel.Model_III:\"cross_price\",\n",
    "        # StructuralModel.Model_IV:\"complex_model\",\n",
    "    }\n",
    "\n",
    "    demand_equation = {\n",
    "        StructuralModel.Model_I:'$D_{t} = D_0 + \\\\beta^{P}P_{t} + \\\\beta^{D1}D_{t-1} + U_{t}^{d}$',\n",
    "        StructuralModel.Model_II:'$D_t = D_0 + \\\\beta^{P}P_t + \\\\beta^{B1}B_{t-1} + U_{t}^{d}$',\n",
    "        # StructuralModel.Model_III:'$D_t = D_0 + \\\\beta_{P0}P_t + \\\\beta_{P1}P_{t-1} + \\\\epsilon_t^d$',\n",
    "        # StructuralModel.Model_IV:\"complex_model\",\n",
    "    }\n",
    "\n",
    "    demand_arg = {\n",
    "        StructuralModel.Model_I:'str. autocorr. of demand',\n",
    "        StructuralModel.Model_II:'str. autocorr. of demand',\n",
    "        # StructuralModel.Model_III:'Cross-price elasticity ($\\\\beta_{P1}$)',\n",
    "        # StructuralModel.Model_IV:\"complex_model\",\n",
    "    }\n",
    "\n",
    "    fig, axs = plt.subplots(2, len(models), sharex=False,  sharey=False, figsize=(WIDE_WIDTH, HEIGHT*2))\n",
    "\n",
    "    for i, model in enumerate(models):\n",
    "\n",
    "        name = f\"punchline_output_{name_dict[model]}_{sample//8760}_years_{runs}_runs_{linspace}_linspace\"+file\n",
    "        df = get_results_punchline(name, list(color_estimator_dict.values()), sample, runs, linspace, model=model)\n",
    "\n",
    "\n",
    "        plot_punchline_panel(axs[i][1], df, color_estimator_dict, \n",
    "                             xlim=(-0.25, 0.9) if model in [StructuralModel.Model_I, StructuralModel.Model_II] else (-200, 200), \n",
    "                             xlabel=demand_arg[model], \n",
    "                             model_name=demand_equation[model], \n",
    "                             ylabel='estimated demand response $\\\\hat{\\\\beta}^{P}$',\n",
    "                             add_label=True if i == 0 else False)    \n",
    "        axs[i][1].set_ylim(-300, 50)\n",
    "\n",
    "\n",
    "    plot_dag_model_I_on_axes(axes=axs[0][0])\n",
    "    plot_dag_model_II_on_axes(axes=axs[1][0])\n",
    "\n",
    "\n",
    "    axs[0][0].set_title(axs[0][0].get_title(), fontsize=\"large\")\n",
    "    axs[0][1].set_title(\"Estimates from data generated using Model I\", size=\"large\")\n",
    "    axs[1][0].set_title(axs[1][0].get_title(), fontsize=\"large\")\n",
    "    axs[1][1].set_title(\"Estimates from data generated using Model II\", size=\"large\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    handles = punchline_plot_legend(list(color_estimator_dict.values()))\n",
    "\n",
    "\n",
    "    fig.legend(handles=handles, loc=\"upper center\", frameon=False, bbox_to_anchor=(0.5, 0),\n",
    "               fancybox=True, fontsize='large', ncol=2, \n",
    "               handler_map={FancyArrowPatch : HandlerPatch(patch_func=make_legend_arrow)})\n",
    "    \n",
    "    fig.show()\n",
    "\n",
    "    fig_name = f\"punchline_plot_{sample//8760}_years_{runs}_runs_{linspace}_linspace\"+file\n",
    "\n",
    "    save_figure(fig, fig_name, VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "punchline_plot(runs=20, linspace=21, sample=8760*5, color_estimator_dict={\n",
    "    \"dodgerblue\":ModelInputParams(IVOptions.REGULAR, order=26),\n",
    "    \"darkorange\":ModelInputParams(IVOptions.CONDITIONAL_DEMAND, order=1, order_w=0),\n",
    "    \"darkgreen\":ModelInputParams(IVOptions.IV_2dim_ORDER, order=26, order_d=1, order_price=1),\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulations_for_heatmap(\n",
    "    sample: int = 8760,\n",
    "    runs: int = 10,\n",
    "    linspace: int = 21,\n",
    "    estimator: ModelInputParams = ModelInputParams(IVOptions.REGULAR, order=0),\n",
    "    model:StructuralModel = StructuralModel.Model_I,\n",
    "    wind_lags: int = 1,\n",
    ") -> tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \n",
    "    # Create the X and Y axis\n",
    "    \n",
    "    alpha_d = np.linspace(0, 0.999, linspace)\n",
    "    alpha_w = np.linspace(0, 0.999, linspace)\n",
    "\n",
    "\n",
    "    demand_grid, wind_grid = np.meshgrid(alpha_d, alpha_w)\n",
    "    error_values = np.zeros_like(demand_grid)\n",
    "\n",
    "    # For each point on the grid, run {runs} simulations with a demand type that corresponds to the specified model\n",
    "\n",
    "    for i, d in enumerate(alpha_d):\n",
    "        for j, w in enumerate(alpha_w):\n",
    "\n",
    "            simulation = Simulation(sample)\n",
    "\n",
    "            simulation.run_simulations_by_model(runs=runs, estimators=[estimator], model=model, \n",
    "                                                demand_arg=d, wind_manual_ar_sum=w, wind_lags=wind_lags,\n",
    "                                                simulation_count=i*linspace*runs + j*runs)\n",
    "                \n",
    "            error_values[i, j] = simulation.models[estimator.name].average_percentage_error\n",
    "            \n",
    "\n",
    "    return alpha_d, alpha_w, error_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_error_grid_to_csv(alpha_values, beta_values, error_values, filename):\n",
    "    \"\"\"\n",
    "    Export Error values to a CSV file.\n",
    "    \n",
    "    Parameters:\n",
    "        alpha_values (numpy.ndarray): Array of alpha values.\n",
    "        beta_values (numpy.ndarray): Array of beta values.\n",
    "        e_values (numpy.ndarray): Array of E-values.\n",
    "        filename (str): Name of the CSV file to export.\n",
    "    \"\"\"\n",
    "    with open(FOLDER+filename+\".csv\", 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        # Write header row\n",
    "        writer.writerow(['alpha_demand', 'alpha_wind', 'error'])\n",
    "        # Write data rows\n",
    "        for i in range(len(alpha_values)):\n",
    "            for j in range(len(beta_values)):\n",
    "                writer.writerow([alpha_values[i], beta_values[j], error_values[i, j]])\n",
    "\n",
    "def retrieve_error_grid_from_csv(filename):\n",
    "    \"\"\"\n",
    "    Retrieve Error values from a CSV file in a grid format\n",
    "    \n",
    "    Parameters:\n",
    "        filename (str): Name of the CSV file to retrieve data from.\n",
    "    \n",
    "    Returns:\n",
    "        alpha_grid (numpy.ndarray): 2D grid of alpha values.\n",
    "        beta_grid (numpy.ndarray): 2D grid of beta values.\n",
    "        error_grid (numpy.ndarray): 2D grid of error values.\n",
    "    \"\"\"\n",
    "    alpha_values = []\n",
    "    beta_values = []\n",
    "    e_values = []\n",
    "    \n",
    "    with open(FOLDER+filename+'.csv', 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        next(reader)  # Skip header row\n",
    "        for row in reader:\n",
    "            alpha_values.append(float(row[0]))\n",
    "            beta_values.append(float(row[1]))\n",
    "            e_values.append(float(row[2]))\n",
    "    \n",
    "    alpha_values = np.unique(alpha_values)\n",
    "    beta_values = np.unique(beta_values)\n",
    "    e_values = np.array(e_values).reshape(len(alpha_values), len(beta_values))\n",
    "\n",
    "    alpha_grid, beta_grid = np.meshgrid(alpha_values, beta_values)\n",
    "    \n",
    "    return alpha_grid, beta_grid, e_values.reshape(alpha_grid.shape)\n",
    "\n",
    "def get_results_heatmap(file_path:str, estimator:ModelInputParams, sample:int, runs:int, linspace:int, wind_lags:int, model:StructuralModel) -> tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    try:\n",
    "        alpha_demand, alpha_wind, error_grid = retrieve_error_grid_from_csv(file_path)            \n",
    "    except FileNotFoundError as e:\n",
    "        print(e)\n",
    "        alpha_demand, alpha_wind, error_grid = run_simulations_for_heatmap(sample=sample, runs=runs, linspace=linspace, estimator=estimator, model=model, wind_lags=wind_lags)\n",
    "        export_error_grid_to_csv(alpha_demand, alpha_wind, error_grid, file_path)\n",
    "\n",
    "    return alpha_demand, alpha_wind, error_grid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap_panel(fig:Figure, axes:Axes, alpha_grid, beta_grid, error_values:np.ndarray, xlabel:str, model_name:str, ylabel:str):\n",
    "    axes.set_xlabel(xlabel, fontsize='large')\n",
    "    axes.set_ylabel(ylabel, fontsize='large')\n",
    "    axes.set_title(model_name, fontsize='large')\n",
    "    axes.set_ylim(-0.01, 1)\n",
    "    axes.set_xlim(-0.01, 1)\n",
    "\n",
    "    \n",
    "    axes.contour(alpha_grid, beta_grid, abs(error_values.transpose()), levels=[1], colors='darkgreen', linestyles='solid', lw=2)\n",
    "    axes.contour(alpha_grid, beta_grid, abs(error_values.transpose()), levels=[5], colors='lightgreen', linestyles=[(5, (10, 3))])\n",
    "    axes.contour(alpha_grid, beta_grid, abs(error_values.transpose()), levels=[10], colors='gold', linestyles='dashed')\n",
    "    axes.contour(alpha_grid, beta_grid, abs(error_values.transpose()), levels=[25], colors='darkorange', linestyles='dashdot')\n",
    "    axes.contour(alpha_grid, beta_grid, abs(error_values.transpose()), levels=[50], colors='red', linestyles='dotted')\n",
    "    axes.contour(alpha_grid, beta_grid, abs(error_values.transpose()), levels=[100], colors='purple', linestyles=[(5, (1, 4))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap_legend():\n",
    "    handles=[Line2D([0], [0], color=\"darkgreen\", ls=\"solid\", lw=2),\n",
    "            Line2D([0], [0], color=\"lightgreen\", ls=(5, (10, 3)), lw=2),\n",
    "            Line2D([0], [0], color=\"gold\", ls='dashed', lw=2),\n",
    "            Line2D([0], [0], color=\"darkorange\", ls=\"dashdot\", lw=2),\n",
    "            Line2D([0], [0], color=\"red\", ls='dotted', lw=2),\n",
    "            Line2D([0], [0], color=\"purple\", ls=(5, (1, 4)), lw=2)]\n",
    "    \n",
    "    labels=[\"1% error line\", \n",
    "            \"5% error line\", \n",
    "            \"10% error line\", \n",
    "            \"25% error line\", \n",
    "            \"50% error line\", \n",
    "            \"100% error line\"]\n",
    "    \n",
    "    return handles, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap(runs=10, linspace=25, sample=8760, wind_lags:int=1,\n",
    "            estimator1:ModelInputParams=ModelInputParams(IVOptions.REGULAR, 0), \n",
    "            estimator2:ModelInputParams=ModelInputParams(IVOptions.CONDITIONAL_DEMAND, 1, order_w=0), \n",
    "            file:str=\"\", \n",
    "            model_1:StructuralModel = StructuralModel.Model_I,\n",
    "            model_2:StructuralModel = StructuralModel.Model_II,\n",
    "            double:bool = True,\n",
    "):\n",
    "\n",
    "    name_dict = {\n",
    "        StructuralModel.Model_I:\"simple_model\",\n",
    "        StructuralModel.Model_III:\"cross_price\",\n",
    "        StructuralModel.Model_II:\"autocorrelated_error\",\n",
    "        StructuralModel.Model_IV:\"complex_model\",\n",
    "    }\n",
    "\n",
    "    name_1 = f\"heatmap_{name_dict[model_1]}_{estimator1.strategy}_{sample//8760}_years_{runs}_runs_{linspace}_linspace_{wind_lags}_windlags\".replace(\"IVOptions.\", \"\")\n",
    "    name_2 = f\"heatmap_{name_dict[model_2]}_{estimator2.strategy}_{sample//8760}_years_{runs}_runs_{linspace}_linspace_{wind_lags}_windlags\".replace(\"IVOptions.\", \"\")\n",
    "\n",
    "    if double:\n",
    "        fig, axs = plt.subplots(1, 2, sharex=False,  sharey=False, figsize=(WIDE_WIDTH, HEIGHT))\n",
    "    else:\n",
    "        fig, axs = plt.subplots(1, 1, sharex=False,  sharey=False, figsize=(4.5, 4.5))\n",
    "\n",
    "\n",
    "    fig_name = f\"heatmap_{sample//8760}_years_{runs}_runs_{linspace}_linspace_{wind_lags}_windlags{'_double' if double else '_single'}\"+file\n",
    "    \n",
    "    def _model_name(model:StructuralModel) -> str:\n",
    "        return str(model).replace(\"StructuralModel.\", \"\").replace(\"_\", \" \")\n",
    "    \n",
    "    num1 = \"#1 \" if estimator1.strategy == IVOptions.REGULAR else \"#3 \" if estimator1.strategy == IVOptions.CONDITIONAL_DEMAND else \"\"\n",
    "    num2 = \"#1 \" if estimator2.strategy == IVOptions.REGULAR else \"#3 \" if estimator2.strategy == IVOptions.CONDITIONAL_DEMAND else \"\"\n",
    "\n",
    "    alpha_demand, alpha_wind, error_grid = get_results_heatmap(name_1, estimator1, sample, runs, linspace, model=model_1, wind_lags=wind_lags)\n",
    "    plot_heatmap_panel(fig, axs[0] if double else axs, alpha_demand, alpha_wind, error_grid,\n",
    "                       ylabel=\"str. autocorrelation of demand ($\\\\beta^{D1}$)\" if model_1 == StructuralModel.Model_I else \"str. autocorrelation of price-insensitive demand ($\\\\beta^{B1}$)\",\n",
    "                       xlabel=\"str. autocorrelation of wind ($\\\\beta^W$)\",\n",
    "                       model_name=num1+estimator1.latex_name+' on '+_model_name(model_1))\n",
    "    if double:\n",
    "        alpha_demand, alpha_wind, error_grid = get_results_heatmap(name_2, estimator2, sample, runs, linspace, model=model_2, wind_lags=wind_lags)\n",
    "        plot_heatmap_panel(fig, axs[1], alpha_demand, alpha_wind, error_grid, \n",
    "                        ylabel=\"str. autocorrelation of non price\\nresponsive demand $\\\\beta^{B1}$\",\n",
    "                        xlabel=\"str. autocorrelation of wind $\\\\beta^W1$\",\n",
    "                        model_name=num2+estimator2.latex_name+' on '+_model_name(model_2))\n",
    "    \n",
    "    handles, labels = heatmap_legend()\n",
    "\n",
    "    fig.legend(handles=handles, labels=labels,\n",
    "                loc=\"upper center\", frameon=False, bbox_to_anchor=(0.5, 0), fancybox=True, fontsize='large', ncols=3)\n",
    "    fig.tight_layout()\n",
    "    fig.show()\n",
    "\n",
    "    save_figure(fig, fig_name, VERSION)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap(20, 10, 8760*5, double=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appendix figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap(20, 10, 8760*5, double=False, estimator1=ModelInputParams(IVOptions.CONDITIONAL_DEMAND, 1, order_w=0), model_1=StructuralModel.Model_II, file=\"_appendix_version\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observed AR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_bias_and_observed_autocorrelation(\n",
    "    sample: int = 8760,\n",
    "    runs: int = 3,\n",
    "    linspace: int = 50,\n",
    "    wind_manual_ar_sum: float | None = None,\n",
    "    estimator: ModelInputParams = ModelInputParams(IVOptions.REGULAR, order=0),\n",
    "    models:list[StructuralModel] = [StructuralModel.Model_I, StructuralModel.Model_II, StructuralModel.Model_III]\n",
    ") -> dict[str, list[tuple[float, float]]]:\n",
    "    \n",
    "    name_dict = {\n",
    "        StructuralModel.Model_I:\"simple_model\",\n",
    "        StructuralModel.Model_II:\"autocorrelated_error\",\n",
    "        StructuralModel.Model_III:\"cross_price\",\n",
    "        StructuralModel.Model_IV:\"complex_model\",\n",
    "    }\n",
    "\n",
    "    # Create the X axis\n",
    "    \n",
    "    xx = np.linspace(-250, 250, linspace)\n",
    "    dd = np.linspace(-0.249, 0.999, linspace)\n",
    "\n",
    "    models_results_dict:dict[str, list[tuple[float, float]]] = {}\n",
    "\n",
    "    # For each point on the x axis, run {runs} simulations with a demand type that corresponds to the specified model\n",
    "    for model in models:\n",
    "        model_list:list[tuple[float, float]] = []\n",
    "        for i in range(linspace):\n",
    "            d = dd[i]\n",
    "            x = xx[i]\n",
    "            random_integers: list[int] = random.sample(range(1, 1000001), runs)\n",
    "\n",
    "            for n, seed in enumerate(random_integers):\n",
    "                np.random.seed(seed)\n",
    "\n",
    "                simulation = Simulation(sample)\n",
    "                eq = simulation.get_equilibrium(demand=simulation.get_demand(model, d if model in [StructuralModel.Model_I, StructuralModel.Model_II] else x),\n",
    "                                                supply=simulation.get_supply(wind_manual_ar_sum, wind_lags=1))                \n",
    "                \n",
    "                ar_params = ar_model_analysis(ar_model_fit(eq.clearing.demand, 1, exog=None))\n",
    "\n",
    "                simulation.analyze_equilibrium(eq, [estimator], False, False)\n",
    "                \n",
    "                error = (-100-simulation.models[estimator.name].estimates[-1])/(-100)*100\n",
    "                model_list.append((ar_params.lags_dict[-1], error))\n",
    "\n",
    "                print(f\"Simulation {i*runs+n} seed {seed} ({model})\")\n",
    "\n",
    "        models_results_dict[name_dict[model]] = model_list\n",
    "            \n",
    "\n",
    "    return models_results_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_observed_ar_to_csv(models_results_dict: dict[str, list[tuple[float, float]]], filename: str):\n",
    "    with open(FOLDER+filename+'.csv', 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        for key, value in models_results_dict.items():\n",
    "            writer.writerow([key] + [f'{x},{y}' for x, y in value])\n",
    "\n",
    "def load_observed_ar_from_csv(filename: str) -> dict[str, list[tuple[float, float]]]:\n",
    "    models_results_dict = {}\n",
    "    with open(FOLDER+filename+'.csv', 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        for row in reader:\n",
    "            key = row[0]\n",
    "            values = [(float(pair.split(',')[0]), float(pair.split(',')[1])) for pair in row[1:]]\n",
    "            models_results_dict[key] = values\n",
    "    return models_results_dict\n",
    "\n",
    "def get_observed_ar_results(file_path:str, estimator:ModelInputParams, sample:int, runs:int, linspace:int, models:list[StructuralModel]) -> dict[str, list[tuple[float, float]]]:\n",
    "    try:\n",
    "        models_results_dict = load_observed_ar_from_csv(file_path)            \n",
    "    except FileNotFoundError:\n",
    "        models_results_dict = run_bias_and_observed_autocorrelation(sample=sample, runs=runs, linspace=linspace, estimator=estimator, models=models)\n",
    "        save_observed_ar_to_csv(models_results_dict, file_path)\n",
    "\n",
    "    return models_results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_observed_ar_panel(axes:Axes, models_results_dict: dict[str, list[tuple[float, float]]], runs:int, title:str, legend:bool=True):\n",
    "    model_names = [\"Model I\", \"Model II\", \"Model III\"]\n",
    "    markers = ['.', '*', '^']\n",
    "    cmaps = ['Blues', 'Oranges', 'Greens']\n",
    "    colors = ['dodgerblue', 'darkorange', 'darkgreen']\n",
    "\n",
    "    axes.axhline(0, 0, 1, color='black', linewidth=0.8)\n",
    "\n",
    "\n",
    "    zz = []\n",
    "    n = len(models_results_dict['simple_model'])\n",
    "    for z in np.linspace(-250, 250, n//runs):\n",
    "        for i in range(runs):\n",
    "            zz.append(z)\n",
    "    \n",
    "    for i, (key, values) in enumerate(models_results_dict.items()):\n",
    "        sorted_values = sorted(values[:n-runs], key=lambda x: x[0])\n",
    "        \n",
    "        xx = [pair[0] for pair in values[:n-runs]]\n",
    "        yy = [pair[1] for pair in values[:n-runs]]\n",
    "        # axes.scatter(xx, yy, c=colors[i], label=model_names[i]+f\" ({key})\", marker=markers[i], alpha=0.5)\n",
    "        axes.scatter(xx, yy, c=zz[:n-runs], cmap=cmaps[i], label=model_names[i]+f\" ({key})\", marker=markers[i], alpha=1)\n",
    "\n",
    "\n",
    "    axes.set_ylim(-305, 305)\n",
    "    axes.set_xlim(0, 1)\n",
    "\n",
    "\n",
    "    axes.set_xlabel('observed autocorrelation of demand $\\\\alpha^{D1}$', size=\"large\")\n",
    "    axes.set_ylabel('percentage error', size=\"large\")\n",
    "    axes.set_title(title)\n",
    "    if legend:\n",
    "        axes.legend()\n",
    "    axes.grid(True)\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def observed_ar_legend():\n",
    "    def _get_mid_color(cmap_name:str) -> str:\n",
    "        cmap = plt.get_cmap(cmap_name)\n",
    "        norm = plt.Normalize(vmin=0, vmax=1)    # type: ignore\n",
    "\n",
    "        sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "        sm.set_array([])\n",
    "\n",
    "        color_at_middle = sm.to_rgba(0.7)       # type: ignore\n",
    "\n",
    "        return mcolors.to_hex(color_at_middle)  # type: ignore\n",
    "\n",
    "    handles = [\n",
    "        Line2D([0], [0], marker='.', color='w', markerfacecolor=_get_mid_color('Blues'), markersize=10),\n",
    "        Line2D([0], [0], marker='*', color='w', markerfacecolor=_get_mid_color('Oranges'), markersize=10),\n",
    "        Line2D([0], [0], marker='^', color='w', markerfacecolor=_get_mid_color('Greens'), markersize=8)\n",
    "    ]\n",
    "\n",
    "    labels = ['Model I', 'Model II', 'Model III']\n",
    "\n",
    "    return handles, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def observed_ar(runs=10, linspace=21, sample=8760, estimator:ModelInputParams= ModelInputParams(IVOptions.REGULAR, 0)):\n",
    "    fig, axes = plt.subplots(1, 1, sharex=True, sharey=True, figsize=(REGULAR_WIDTH, HEIGHT))\n",
    "    fig_name = f\"observed_ar_{sample//8760}_years_{runs}_runs_{linspace}_linspace_{estimator.strategy}\".replace(\"IVOptions.\", \"\")\n",
    "\n",
    "    results = get_observed_ar_results(fig_name, estimator, sample, runs, linspace, \n",
    "                                      models=[StructuralModel.Model_I, StructuralModel.Model_II, StructuralModel.Model_III])\n",
    "    \n",
    "    num = \"#1 \" if estimator.strategy == IVOptions.REGULAR else \"#3 \" if estimator.strategy == IVOptions.CONDITIONAL_DEMAND else \"\"\n",
    "\n",
    "    plot_observed_ar_panel(axes, results, runs, title=num+estimator.latex_name, legend=False)\n",
    "\n",
    "    handles, labels = observed_ar_legend()\n",
    "\n",
    "    fig.legend(handles, labels, loc=\"upper center\", frameon=False, bbox_to_anchor=(0.5, 0), fancybox=True, fontsize='large', ncol=3)\n",
    "\n",
    "    save_figure(fig, fig_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_ar(4, 100, sample=8760*5, estimator=ModelInputParams(IVOptions.REGULAR, order=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_ar(4, 100, sample=8760*5, estimator=ModelInputParams(IVOptions.CONDITIONAL_DEMAND, order=1, order_w=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_panel_observed_ar(runs=10, linspace=21, sample=8760, \n",
    "                             estimator1:ModelInputParams= ModelInputParams(IVOptions.REGULAR, 0), \n",
    "                             estimator2:ModelInputParams= ModelInputParams(IVOptions.CONDITIONAL_DEMAND, 1, order_w=0)):\n",
    "    fig, [ax1, ax2] = plt.subplots(1, 2, sharex=True, sharey=True, figsize=(WIDE_WIDTH, HEIGHT))\n",
    "\n",
    "    fig_name_1 = f\"observed_ar_{sample//8760}_years_{runs}_runs_{linspace}_linspace_{estimator1.strategy}\".replace(\"IVOptions.\", \"\")\n",
    "    fig_name_2 = f\"observed_ar_{sample//8760}_years_{runs}_runs_{linspace}_linspace_{estimator2.strategy}\".replace(\"IVOptions.\", \"\")\n",
    "\n",
    "    models = [StructuralModel.Model_I, StructuralModel.Model_II, StructuralModel.Model_III]\n",
    "\n",
    "    results1 = get_observed_ar_results(fig_name_1, estimator1, sample, runs, linspace, \n",
    "                                       models=models)\n",
    "    results2 = get_observed_ar_results(fig_name_2, estimator2, sample, runs, linspace, \n",
    "                                       models=models)\n",
    "\n",
    "    plot_observed_ar_panel(ax1, results1, runs, \"a)   \"+estimator1.latex_name, False)\n",
    "    plot_observed_ar_panel(ax2, results2, runs, \"b)   \"+estimator2.latex_name, False)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    handles, labels = observed_ar_legend()\n",
    "\n",
    "    fig.legend(handles, labels, loc=\"upper center\", frameon=False, bbox_to_anchor=(0.5, 0), fancybox=True, fontsize='large')\n",
    "\n",
    "\n",
    "    save_figure(fig, f\"double_panel_observed_ar_{sample//8760}_years_{runs}_runs_{linspace}_linspace\")\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "double_panel_observed_ar(4, 100, 8760*5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined heatmap and observed AR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_heatmap_and_observed_ar_plot(\n",
    "        heatmap_runs:int,\n",
    "        heatmap_linspace:int,\n",
    "        observed_ar_runs:int,\n",
    "        observed_ar_linspace:int,\n",
    "        sample:int,\n",
    "        estimator:ModelInputParams):\n",
    "    \n",
    "    if estimator.strategy == IVOptions.REGULAR:\n",
    "        model = StructuralModel.Model_I\n",
    "    elif estimator.strategy == IVOptions.CONDITIONAL_DEMAND:\n",
    "        model = StructuralModel.Model_II\n",
    "    else:\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    name_dict = {\n",
    "        StructuralModel.Model_I:\"simple_model\",\n",
    "        StructuralModel.Model_III:\"cross_price\",\n",
    "        StructuralModel.Model_II:\"autocorrelated_error\",\n",
    "        StructuralModel.Model_IV:\"complex_model\",\n",
    "    }\n",
    "\n",
    "    # HEATMAP\n",
    "\n",
    "    heatmap_name = f\"heatmap_{name_dict[model]}_{estimator.strategy}_{sample//8760}_years_{heatmap_runs}_runs_{heatmap_linspace}_linspace\".replace(\"IVOptions.\", \"\")\n",
    "    \n",
    "    fig, [ax1, ax2] = plt.subplots(1, 2, sharex=False, sharey=False, figsize=(WIDE_WIDTH, HEIGHT))\n",
    "\n",
    "    alpha_grid, beta_grid, errors = get_results_heatmap(heatmap_name, estimator, sample, heatmap_runs, heatmap_linspace, 1, model)\n",
    "    \n",
    "    plot_heatmap_panel(fig, ax1, alpha_grid, beta_grid, errors,\n",
    "                       ylabel=\"str. autocorrelation of demand ($\\\\beta^{D1}$)\",\n",
    "                       xlabel=\"str. autocorrelation of wind ($\\\\beta^W$)\",\n",
    "                       model_name='a) Bias of '+estimator.latex_name+f' on {model}'.replace('_', ' ').replace(\"StructuralModel.\", \"\"))\n",
    "\n",
    "    # OBSERVED AR\n",
    "\n",
    "    observed_ar_name = f\"observed_ar_{sample//8760}_years_{observed_ar_runs}_runs_{observed_ar_linspace}_linspace_{estimator.strategy}\".replace(\"IVOptions.\", \"\")\n",
    "\n",
    "    models_results_dict = get_observed_ar_results(observed_ar_name, estimator, sample, observed_ar_runs, observed_ar_linspace, \n",
    "                                                  models=[StructuralModel.Model_I, StructuralModel.Model_II, StructuralModel.Model_III])\n",
    "\n",
    "    title = \"b) Lack of correlation between $\\\\alpha^{D1}$ and bias\"\n",
    "\n",
    "    plot_observed_ar_panel(ax2, models_results_dict, observed_ar_runs, title, legend=False)\n",
    "\n",
    "    handles_1, labels_1 = heatmap_legend()\n",
    "\n",
    "    handles_2, labels_2 = observed_ar_legend()\n",
    "\n",
    "    handles = handles_1+handles_2\n",
    "    labels = labels_1+labels_2\n",
    "\n",
    "    fig.legend(handles, labels, loc=\"upper center\", frameon=False, bbox_to_anchor=(0.5, 0), fancybox=True, fontsize='large', ncol=3)\n",
    "\n",
    "    save_figure(fig, f\"combined_heatmap_and_observed_ar\")\n",
    "    fig.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_heatmap_and_observed_ar_plot(heatmap_runs=20, heatmap_linspace=10,\n",
    "#                                       observed_ar_runs=4, observed_ar_linspace=100,\n",
    "#                                       sample=8760*5, \n",
    "#                                       estimator=ModelInputParams(IVOptions.REGULAR, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_estimator_indicator_analysis(estimator:ModelInputParams, max_sample:int=50, runs:int=10, linspace:int=7, wind_manual_ar_sum=None, alpha=0.05, model:StructuralModel=StructuralModel.Model_I, min_sample=1):\n",
    "    xx = [round(x) for x in np.linspace(min_sample, max_sample, linspace)]\n",
    "\n",
    "    yy_error = []\n",
    "    yy_error_lower = []\n",
    "    yy_error_upper = []\n",
    "\n",
    "    yy_distance = []\n",
    "    yy_distance_lower = []\n",
    "    yy_distance_upper = []\n",
    "\n",
    "    yy_coverage = []\n",
    "    yy_coverage_lower = []\n",
    "    yy_coverage_upper = []\n",
    "\n",
    "    for i, x in enumerate(xx):\n",
    "        sample = x * 8760\n",
    "\n",
    "        simulation = Simulation(sample)\n",
    "\n",
    "        simulation.run_simulations_by_model(runs, \n",
    "                                            estimators=[estimator],\n",
    "                                            model=model,\n",
    "                                            demand_arg=None, \n",
    "                                            simulation_count=i*runs)\n",
    "\n",
    "        if estimator.name in simulation.models.keys():\n",
    "            name = estimator.name\n",
    "        else:\n",
    "            name = estimator.name+\"_P0\"\n",
    "\n",
    "        yy_error.append(simulation.models[name].average_absolute_percentage_error)\n",
    "        error_low, error_up = ws.DescrStatsW(simulation.models[name].absolute_percentage_errors).tconfint_mean(alpha=alpha)\n",
    "        if any(e < 0 for e in simulation.models[name].absolute_percentage_errors):\n",
    "            raise Exception(\"Some errors are negative\")\n",
    "        print(f\"ERRORS\\nfrom {simulation.models[name].absolute_percentage_errors}\\n\\tmean:{simulation.models[name].average_absolute_percentage_error}\\n\\tupper:{error_up}\\n\\tlower:{error_low}\")\n",
    "        yy_error_lower.append(error_low)\n",
    "        yy_error_upper.append(error_up)\n",
    "\n",
    "        yy_distance.append(simulation.models[name].average_distance)\n",
    "        distance_low, distance_up = ws.DescrStatsW(simulation.models[name].ci_upper_bound).tconfint_mean(alpha=alpha)\n",
    "        if any(e < 0 for e in simulation.models[name].ci_upper_bound):\n",
    "            raise Exception(\"Some distances are negative\")\n",
    "        yy_distance_lower.append(distance_low)\n",
    "        yy_distance_upper.append(distance_up)\n",
    "\n",
    "\n",
    "        yy_coverage.append(simulation.models[name].average_coverage)\n",
    "        coverage_low, coverage_up = proportion.proportion_confint(simulation.models[name].coverage_count, simulation.models[name].n, alpha=alpha)\n",
    "        if coverage_low < 0:\n",
    "            raise Exception(\"Coverage low is lower than 0!\")\n",
    "        if coverage_up > 1:\n",
    "            raise Exception(\"Coverage up is higher than 1!\")\n",
    "        yy_coverage_lower.append(coverage_low)\n",
    "        yy_coverage_upper.append(coverage_up)\n",
    "\n",
    "    # Organize results into a DataFrame\n",
    "\n",
    "    sub_index = [\"Mean\", \"Upper\", \"Lower\"]\n",
    "    index = pd.MultiIndex.from_product([[\"Error\", \"Distance\", \"Coverage\"], sub_index])\n",
    "    \n",
    "    data = [\n",
    "        yy_error,\n",
    "        yy_error_upper,\n",
    "        yy_error_lower,\n",
    "        yy_distance,\n",
    "        yy_distance_upper,\n",
    "        yy_distance_lower,\n",
    "        yy_coverage,\n",
    "        yy_coverage_upper,\n",
    "        yy_coverage_lower,\n",
    "    ]\n",
    "\n",
    "    results_df = pd.DataFrame(data, index=index, columns=xx).T\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_goodness_panel_from_indicator(axes:Axes, dfs:list[pd.DataFrame], names:list[str], indicator:str, lables:bool, model:StructuralModel, xlabel:bool=False):\n",
    "    color1 = '#377eb8'\n",
    "    color2 = '#ff7f00'\n",
    "    color3 = '#4daf4a'\n",
    "\n",
    "    colors = [color1, color2, color3]\n",
    "    hatches = ['++', '..', 'XX']\n",
    "\n",
    "    xx = dfs[0].index\n",
    "\n",
    "    indicator_name_dict:dict[str, str] = {\n",
    "        'Coverage':'coverage',\n",
    "        'Error':'absolute percentage error',\n",
    "        'Distance':'length of confidence interval'\n",
    "    }\n",
    "\n",
    "    indicator_ylim:dict[str, tuple[float, float]] = {\n",
    "        'Coverage':(-0.01, 1.01),\n",
    "        'Error':(0, 25 if model == StructuralModel.Model_II else 20),\n",
    "        'Distance':(0, 50 if model == StructuralModel.Model_II else 40)\n",
    "    }\n",
    "    \n",
    "    axes.set_ylabel(indicator_name_dict[indicator], color='k', size=\"large\")\n",
    "\n",
    "    for i, df in enumerate(dfs):\n",
    "\n",
    "        axes.plot(xx, df[indicator]['Mean'], color=colors[i], label=names[i] if lables else '')\n",
    "        axes.fill_between(xx, df[indicator]['Upper'], df[indicator]['Lower'], color=colors[i], alpha=0.4, hatch=hatches[i])\n",
    "        axes.tick_params('y', colors='k')\n",
    "    \n",
    "        axes.set_xlim(1, max(xx))\n",
    "        axes.set_ylim(indicator_ylim[indicator])\n",
    "        if xlabel:\n",
    "            axes.set_xlabel(\"years [sample size / 8760]\", size=\"large\")\n",
    "        axes.set_xticks(xx)\n",
    "\n",
    "    # Create custom legend handles\n",
    "    legend_elements = [\n",
    "        # Line2D([0], [0], color=colors[i], lw=2, label=names[i] if lables else '') for i in range(len(dfs))\n",
    "    # ] + [\n",
    "        Patch(edgecolor=colors[i], facecolor=colors[i], hatch=hatches[i], label=names[i] if lables else '', alpha=0.5) for i in range(len(dfs))\n",
    "    ]\n",
    "\n",
    "    return legend_elements\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_indicators(linspace:int=20, runs:int=50, max_sample:int=30, model:StructuralModel=StructuralModel.Model_I, min_sample:int=1):\n",
    "    fig, axss  = plt.subplots(1, 3, sharex=True, sharey=False, figsize=(EXTRA_WIDTH, HEIGHT))\n",
    "    [axs1, axs2, axs3] = axss\n",
    "\n",
    "    name_dict = {\n",
    "        StructuralModel.Model_I:\"simple_model\",\n",
    "        StructuralModel.Model_II:\"autocorrelated_error\",\n",
    "        StructuralModel.Model_III:\"cross_price\",\n",
    "        StructuralModel.Model_IV:\"complex_model\",\n",
    "    }\n",
    "    _model = name_dict[model]\n",
    "\n",
    "    estimator1 = ModelInputParams(IVOptions.CONDITIONAL_WIND, order=26)\n",
    "    estimator2 = ModelInputParams(IVOptions.CONDITIONAL_H0, order=26)\n",
    "    estimator3 = ModelInputParams(IVOptions.IV_2dim_ORDER, order=26, order_price=1)\n",
    "\n",
    "    estimator_number = {\n",
    "        IVOptions.CONDITIONAL_WIND:2,\n",
    "        IVOptions.IV_2dim_ORDER:8,\n",
    "        IVOptions.RESIDUAL_WIND:8,\n",
    "        IVOptions.CONDITIONAL_H0:4,\n",
    "    }\n",
    "\n",
    "\n",
    "    name_1 = f\"goodness_output_{_model}_{estimator1.strategy}_{max_sample}_years_{runs}_runs_{linspace}_linspace\".replace(\"IVOptions.\", \"\")\n",
    "    name_2 = f\"goodness_output_{_model}_{estimator2.strategy}_{max_sample}_years_{runs}_runs_{linspace}_linspace\".replace(\"IVOptions.\", \"\")\n",
    "    name_3 = f\"goodness_output_{_model}_{estimator3.strategy}_{max_sample}_years_{runs}_runs_{linspace}_linspace\".replace(\"IVOptions.\", \"\")\n",
    "\n",
    "    fig_name = f\"goodness_plot_{_model}_{max_sample}_years_{runs}_runs_{linspace}_linspace\"\n",
    "\n",
    "    try:\n",
    "        df_1 = read_results_from_file(name_1+'.csv')\n",
    "    except FileNotFoundError as e:\n",
    "        print(e) \n",
    "        df_1 = run_estimator_indicator_analysis(min_sample=min_sample, max_sample=max_sample, runs=runs, linspace=linspace, estimator=estimator1, model=model)\n",
    "        write_results_to_file(name_1, df_1)\n",
    "\n",
    "    try:\n",
    "        df_2 = read_results_from_file(name_2+'.csv')\n",
    "    except FileNotFoundError as e:\n",
    "        print(e)\n",
    "        df_2 = run_estimator_indicator_analysis(min_sample=min_sample, max_sample=max_sample, runs=runs, linspace=linspace, estimator=estimator2, model=model)\n",
    "        write_results_to_file(name_2, df_2)\n",
    "\n",
    "    try:\n",
    "        df_3 = read_results_from_file(name_3+'.csv')\n",
    "    except FileNotFoundError as e:\n",
    "        print(e)\n",
    "        df_3 = run_estimator_indicator_analysis(min_sample=min_sample, max_sample=max_sample, runs=runs, linspace=linspace, estimator=estimator3, model=model)\n",
    "        write_results_to_file(name_3, df_3)\n",
    "\n",
    "    estimator1_label = f\"#{estimator_number[estimator1.strategy]} {estimator1.latex_name}\"\n",
    "    estimator2_label = f\"#{estimator_number[estimator2.strategy]} {estimator2.latex_name}\"\n",
    "    estimator3_label = f\"#{estimator_number[estimator3.strategy]} {estimator3.latex_name}\"\n",
    "\n",
    "    labels = [estimator1_label, estimator2_label, estimator3_label]\n",
    "\n",
    "    legend_elements = plot_goodness_panel_from_indicator(axs1, [df_1, df_2, df_3], labels, \"Coverage\", True, model, True)\n",
    "    plot_goodness_panel_from_indicator(axs2, [df_1, df_2, df_3], labels, \"Error\", False, model, True)\n",
    "    plot_goodness_panel_from_indicator(axs3, [df_1, df_2, df_3], labels, \"Distance\", False, model, True)\n",
    "\n",
    "    fig.legend(handles=legend_elements, loc=\"upper center\", frameon=False, bbox_to_anchor=(0.5, 0), fancybox=True, fontsize='large', ncols=1)\n",
    "    fig.show()\n",
    "\n",
    "    save_figure(fig, fig_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_single_estimator_indicator(model:StructuralModel, min_sample:int, max_sample:int, runs:int, linspace:int, estimator:ModelInputParams):\n",
    "    name_dict = {\n",
    "        StructuralModel.Model_I:\"simple_model\",\n",
    "        StructuralModel.Model_II:\"autocorrelated_error\",\n",
    "        StructuralModel.Model_III:\"cross_price\",\n",
    "        StructuralModel.Model_IV:\"complex_model\",\n",
    "    }\n",
    "    _model = name_dict[model]\n",
    "\n",
    "    if min_sample == 1:\n",
    "        name_1 = f\"goodness_output_{_model}_{estimator.strategy}_{max_sample}_years_{runs}_runs_{linspace}_linspace\".replace(\"IVOptions.\", \"\")\n",
    "    else:\n",
    "        name_1 = f\"goodness_output_{_model}_{estimator.strategy}_{min_sample}-{max_sample}_years_{runs}_runs_{linspace}_linspace\".replace(\"IVOptions.\", \"\")\n",
    "    df_1 = run_estimator_indicator_analysis(min_sample=min_sample, max_sample=max_sample, runs=runs, linspace=linspace, estimator=estimator, model=model)\n",
    "    write_results_to_file(name_1, df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_single_estimator_indicator(StructuralModel.Model_I, 15, 21, 1, 6, \n",
    "#                                ModelInputParams(IVOptions.CONDITIONAL_H0, order=26))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_indicators(11, 50, 21, StructuralModel.Model_I, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_indicators(11, 50, 21, StructuralModel.Model_II, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_indicators(11, 50, 21, StructuralModel.Model_III, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=[\n",
    "        ModelInputParams(IVOptions.REGULAR, order=0),\n",
    "        ModelInputParams(IVOptions.CONDITIONAL_WIND, order=26),\n",
    "        ModelInputParams(IVOptions.CONDITIONAL_DEMAND, order=1, order_w=0),\n",
    "        ModelInputParams(IVOptions.CONDITIONAL_H0, order=26),\n",
    "        ModelInputParams(IVOptions.TRUNCATED_NUISANCE_ORDER, order=26, order_d=1),\n",
    "        ModelInputParams(IVOptions.CLEAN_2dim_ORDER, order=26, order_price=1),\n",
    "        ModelInputParams(IVOptions.TRUNCATED_IV_2dim_ORDER, order=26, order_price=1),\n",
    "        ModelInputParams(IVOptions.IV_2dim_ORDER, order=26, order_price=1),\n",
    "        ]\n",
    "\n",
    "\n",
    "def run_model_simulation(sample:int, estimators:list[ModelInputParams], runs:int, model:StructuralModel) -> tuple[list[list[float]], list[list[float]], list[str]]:\n",
    "    simulation = Simulation(sample=sample)\n",
    "\n",
    "    \n",
    "    simulation.run_simulations_by_model(runs=runs,\n",
    "                                        estimators=estimators,\n",
    "                                        model=model,\n",
    "                                        demand_arg=0.7 if model == StructuralModel.Model_I else None)\n",
    "    \n",
    "    results_p0:list[list[float]] = []\n",
    "    results_p1:list[list[float]] = []\n",
    "    names = [est.latex_name for est in estimators]\n",
    "    prev_model = list(simulation.models.keys())[0].split(\"_\")[0]\n",
    "\n",
    "    for name, estimator_results in simulation.models.items():\n",
    "        print(name, estimator_results.results)\n",
    "\n",
    "        new_model = name.split(\"_\")[0]\n",
    "        if new_model != prev_model:\n",
    "            prev_model = new_model\n",
    "            for res_list in [results_p1]:\n",
    "                if len(res_list) < len(results_p0):\n",
    "                    res_list.append([])\n",
    "                \n",
    "        if \"_\" not in name or name.endswith(\"_P0\"):\n",
    "            results_p0.append([res.estimate for res in estimator_results.results])\n",
    "        elif name.endswith(\"_P1\"):\n",
    "            results_p1.append([res.estimate for res in estimator_results.results])\n",
    "    # This is needed just in case the last one also does not have an estimate for all of them!\n",
    "    for res_list in [results_p1]:\n",
    "        if len(res_list) < len(results_p0):\n",
    "            res_list.append([])\n",
    "\n",
    "    return results_p0, results_p1, names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_application_boxplot_results_from_csv(file_path:str) -> tuple[list[list[float]], list[list[float]], list[str]]:\n",
    "    try:\n",
    "        df:pd.DataFrame = pd.read_csv(FOLDER+file_path, index_col=0)\n",
    "        results_p0, results_p1, names = [], [], []\n",
    "\n",
    "        for col in df.columns:\n",
    "            if col.endswith(\"_P0\"):\n",
    "                results_p0.append(list(df[col].values))\n",
    "                names.append(col.removesuffix(\"_P0\"))\n",
    "\n",
    "            elif col.endswith(\"_P1\"):\n",
    "                results_p1.append(list(df[col].values))\n",
    "\n",
    "            else:\n",
    "                raise ValueError(f\"Unexpected column name {col} in file {file_path}\")\n",
    "            \n",
    "        return results_p0, results_p1, names\n",
    "    \n",
    "    except FileNotFoundError as e:\n",
    "        raise e\n",
    "\n",
    "def save_application_boxplot_results(results_p0:list[list[float]], results_p1:list[list[float]], names:list[str], file_path:str, runs:int):\n",
    "    data:dict[str, list[float]] = {}\n",
    "\n",
    "    for i, name in enumerate(names):\n",
    "        data[name+\"_P0\"] = results_p0[i] if results_p0[i] else [np.nan for i in range(runs)]\n",
    "        data[name+\"_P1\"] = results_p1[i] if results_p1[i] else [np.nan for i in range(runs)]\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(FOLDER+file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_application_boxplot_results(model:StructuralModel, sample:int, runs:int, estimators:list[ModelInputParams], file_path:str) -> tuple[list[list[float]], list[list[float]], list[str]]:\n",
    "    file_path = \"application_figure_\"+file_path+f\"_{sample//8760}_years_{runs}_runs.csv\"\n",
    "    \n",
    "    try:\n",
    "        results_p0, results_p1, names = read_application_boxplot_results_from_csv(file_path) \n",
    "\n",
    "        # If there are less results that asked for, run the estimators that are missing\n",
    "        missing_estimators = [estimator for estimator in estimators if estimator.latex_name not in names]\n",
    "        if missing_estimators:\n",
    "            print(\"There are missing estimators:\\n\", [estimator.name for estimator in missing_estimators], \"\\n are not in \\n\", names)\n",
    "            new_results_p0, new_results_p1, new_names = run_model_simulation(sample=sample, runs=runs, estimators=missing_estimators, model=model)\n",
    "            results_p0 = results_p0 + new_results_p0\n",
    "            results_p1 = results_p1 + new_results_p1\n",
    "            names = names + new_names\n",
    "            save_application_boxplot_results(results_p0, results_p1, names, file_path, runs=runs)\n",
    "        \n",
    "        # If there are more results that asked for, drop unwanted results\n",
    "        if len(names) > len(estimators):\n",
    "            estim_names = [estimator.latex_name for estimator in estimators]\n",
    "            filtered_results = [(p0, p1, name) for p0, p1, name in zip(results_p0, results_p1, names) if name in estim_names]\n",
    "            results_p0, results_p1, names = map(list, zip(*filtered_results)) if filtered_results else ([], [], [])\n",
    "\n",
    "\n",
    "        # Ensure the order matches the order of the input estimators\n",
    "        estim_name_to_index = {estimator.latex_name: i for i, estimator in enumerate(estimators)}\n",
    "        ordered_results = sorted(zip(results_p0, results_p1, names), key=lambda x: estim_name_to_index[x[2]])\n",
    "\n",
    "        # Unzip the sorted list back into individual lists\n",
    "        results_p0, results_p1, names = map(list, zip(*ordered_results))\n",
    "\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(e, \"\\nStarting simulation\")\n",
    "        results_p0, results_p1, names = run_model_simulation(sample=sample, runs=runs, estimators=estimators, model=model)\n",
    "        save_application_boxplot_results(results_p0, results_p1, names, file_path, runs=runs)\n",
    "\n",
    "    return results_p0, results_p1, names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def application_boxplot(results_p0:list[list[float]],\n",
    "                        results_p1:list[list[float]], \n",
    "                        names:list[str], \n",
    "                        output_file:str, \n",
    "                        xlim, \n",
    "                        own_price_elasticity, \n",
    "                        cross_price_elasticity,\n",
    "                        replace_ellipsis:bool):\n",
    "        axs:Axes\n",
    "        fig, axs = plt.subplots(1, 1, sharex=False,  sharey=True, figsize=(WIDE_WIDTH, HEIGHT), subplot_kw={'axes_class': axisartist.Axes})\n",
    "   \n",
    "        names = [f\"#{i+1}   {n} \" for i, n in enumerate(names)]\n",
    "        if replace_ellipsis:\n",
    "             names = [func_replace_ellipsis(name) for name in names]\n",
    "        xx_p0: list[list[float]] = list(reversed([[result for result in method_results] for method_results in results_p0]))\n",
    "        xx_p1: list[list[float]] = list(reversed([[result for result in method_results] for method_results in results_p1]))\n",
    "       \n",
    "        ticks: list[str] = list(reversed(names))\n",
    "   \n",
    "        bplot1 = axs.boxplot(xx_p0, vert=False, patch_artist=True)\n",
    "        bplot2 = axs.boxplot(xx_p1, vert=False, patch_artist=True, notch=True)\n",
    "   \n",
    "        colors = [\"darkorange\", \"dodgerblue\"]\n",
    "        bbpp = [bplot1, bplot2]\n",
    "   \n",
    "        for plot, color in zip(bbpp, colors):\n",
    "            for patch in plot['boxes']:\n",
    "                patch.set_facecolor(color)\n",
    "            for median in plot['medians']:\n",
    "                median.set_color('black')\n",
    "   \n",
    "        legend_elements = [\n",
    "            bplot1[\"boxes\"][0], \n",
    "            bplot2[\"boxes\"][0],\n",
    "            Line2D([0], [0], color='darkorange', linestyle=\"--\",),\n",
    "            Line2D([0], [0], color='dodgerblue', linestyle=\":\",),\n",
    "        ]\n",
    "        legend_labels = [\n",
    "            \"estimated own-price demand response $\\\\hat{\\\\beta}^P$ ($P_t\\\\rightarrow D_t$)\", \n",
    "            \"estimated cross-price demand response $\\\\hat{\\\\beta}^{P1}$ ($P_{t-1}\\\\rightarrow D_t$)\",\n",
    "            \"true own-price demand response $\\\\beta^P$\",\n",
    "            \"true cross-price demand response $\\\\beta^{P1}$\",\n",
    "        ]\n",
    "   \n",
    "        axs.tick_params(axis='y', which='both', left=False, labelleft=True, reset=True)\n",
    "   \n",
    "        axs.set_yticks(range(1, len(ticks)+1))\n",
    "        axs.set_yticklabels(ticks, fontsize=\"large\")\n",
    "        axs.yaxis.grid(visible=False)\n",
    "        axs.axis[\"left\"].major_ticklabels.set_ha(\"left\")    # type: ignore\n",
    "        axs.axis[\"left\"].major_ticks.set_ticksize(0)        # type: ignore\n",
    "        \n",
    "\n",
    "        axs.set_ylim(0.5, len(ticks)+0.5)\n",
    "        axs.set_xlim(xlim)\n",
    "        \n",
    "        axs.axvline(x=0, ls='-', color='k', lw=1, alpha=1)\n",
    "        axs.axvline(x=own_price_elasticity, ls='--', color='darkorange', lw=2, alpha=1)\n",
    "        axs.axvline(x=cross_price_elasticity, ls=':', color='dodgerblue', lw=2, alpha=1)\n",
    "   \n",
    "        for h in range(0, len(xx_p0)+1):\n",
    "            axs.axhline(y=h + 0.5, ls=\"-\", color=\"grey\", xmin=-0.425, xmax=1, clip_on=False)\n",
    "    \n",
    "        # Add estimator validity table\n",
    "        plot_table(fig)\n",
    "    \n",
    "        # Add the legend to the figure,\n",
    "        fig.legend(handles=legend_elements, labels=legend_labels, loc='upper center', \n",
    "                   ncol=2, bbox_to_anchor=(0.5, 0), fancybox=True, frameon=False, fontsize=\"large\")\n",
    "    \n",
    "        save_figure(fig, output_file+\"_application_figure\", VERSION)\n",
    "   \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_application_boxplot(sample:int, runs:int, output_file:str, model:StructuralModel, estimators:list[ModelInputParams]):\n",
    "    \n",
    "    results_p0, results_p1, names = get_application_boxplot_results(model=model,\n",
    "                                                                   estimators=estimators,\n",
    "                                                                   sample=sample,\n",
    "                                                                   runs=runs,\n",
    "                                                                   file_path=output_file)\n",
    "    \n",
    "    print(names)\n",
    "    \n",
    "    xlims:dict[StructuralModel, tuple[float, float]] = {\n",
    "        StructuralModel.Model_I:(-400, 100),\n",
    "        StructuralModel.Model_II:(-200, 100),\n",
    "        StructuralModel.Model_III:(-200, 100),\n",
    "    }\n",
    "\n",
    "    application_boxplot(\n",
    "        results_p0=results_p0,\n",
    "        results_p1=results_p1,\n",
    "        names=names,\n",
    "        output_file=output_file,\n",
    "        xlim=xlims[model],\n",
    "        own_price_elasticity=-100,\n",
    "        cross_price_elasticity=50 if model == StructuralModel.Model_III else 0,\n",
    "        replace_ellipsis=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_application_boxplot(8760*5, 100, \"model_I\", StructuralModel.Model_I, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_application_boxplot(8760*5, 100, \"model_II\", StructuralModel.Model_II, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_application_boxplot(8760*5, 100, \"model_III\", StructuralModel.Model_III, models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Singular values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This plot and analysis is not included in the current draft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def covariance(x, y):\n",
    "    return np.mean(x * y) - np.mean(x) * np.mean(y)\n",
    "\n",
    "def cross_covariance_matrix(vector_x, vector_y):\n",
    "    num_x = len(vector_x)\n",
    "    num_y = len(vector_y)\n",
    "\n",
    "    assert num_y >= num_x, \"There must be at least as many instruments as endogeneous variables\"\n",
    "\n",
    "    matrix = np.zeros((num_x, num_y))\n",
    "\n",
    "    for i in range(num_x):\n",
    "        for j in range(num_y):\n",
    "            matrix[i, j] = covariance(vector_x[i], vector_y[j])\n",
    "\n",
    "    return matrix\n",
    "\n",
    "def calculate_eigenvalues(matrix):\n",
    "    eigenvalues, _ = np.linalg.eig(matrix)\n",
    "    return eigenvalues\n",
    "\n",
    "def calculate_singular_values(matrix):\n",
    "    U, singular_values, VT = np.linalg.svd(matrix)\n",
    "    return singular_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_singular_values_analysis(\n",
    "    sample: int = 8760,\n",
    "    runs: int = 10,\n",
    "    linspace: int = 21,\n",
    "    wind_manual_ar_sum: float | None = None,\n",
    "    estimator:ModelInputParams = ModelInputParams(IVOptions.NUISANCE_ORDER, 1),\n",
    "    model:StructuralModel = StructuralModel.Model_III,\n",
    "    instruments: int = 2,\n",
    "    metric:Literal[\"eigenvalues\", \"singular values\"] = \"singular values\"\n",
    ") -> pd.DataFrame:\n",
    "    \n",
    "    # Create the X axis\n",
    "    xx = np.linspace(-200, 200, linspace)\n",
    "    # dd = np.linspace(-0.249, 0.499, linspace)\n",
    "    dd = np.linspace(-0.249, 0.899, linspace)\n",
    "\n",
    "    # Create the empty lists to store the analysis output\n",
    "    mean = []\n",
    "    lower_bound = []\n",
    "    upper_bound = []\n",
    "    matrix_list = []\n",
    "\n",
    "    # Create the simulation instances\n",
    "\n",
    "    for i, x in enumerate(xx):\n",
    "        d = dd[i]\n",
    "\n",
    "        min_metric_value = []\n",
    "        matrix_at_d = []\n",
    "\n",
    "        random_integers: list[int] = random.sample(range(1, 1000001), runs)\n",
    "\n",
    "        for n, seed in enumerate(random_integers):\n",
    "            np.random.seed(seed)\n",
    "\n",
    "            simulation = Simulation(sample)\n",
    "\n",
    "            equilibrium = simulation.get_equilibrium(\n",
    "                demand=simulation.get_demand(model,\n",
    "                                            x if model == StructuralModel.Model_III else d),\n",
    "                supply=simulation.get_supply(wind_manual_ar_sum, 26)\n",
    "            )\n",
    "\n",
    "                \n",
    "            matrix = cross_covariance_matrix(vector_x=[equilibrium.clearing.price, equilibrium.clearing.demand.shift(1)],\n",
    "                                            vector_y=[equilibrium.supply.wind.shift(i) for i in range(instruments)])\n",
    "            \n",
    "            matrix_at_d.append(matrix)\n",
    "            # min_eigenvalue.append(min(calculate_eigenvalues(matrix)))\n",
    "            if metric == \"eigenvalues\":\n",
    "                min_metric_value.append(min([abs(v) for v in calculate_eigenvalues(matrix)]))\n",
    "            elif metric == \"singular values\":\n",
    "                min_metric_value.append(min([abs(v) for v in calculate_singular_values(matrix)]))\n",
    "            else:\n",
    "                raise ValueError(f\"Metric {metric} not implemented\")\n",
    "            run = i*runs+n+1\n",
    "            print(f\"Run {run}/{runs*linspace} finished ({(run)/(runs*linspace)*100}%)\")\n",
    "             \n",
    "        # For each simulation store the output estimates average, upper bound and lower bound\n",
    "\n",
    "        mean.append(np.average(min_metric_value))\n",
    "        low, up = ws.DescrStatsW(min_metric_value).tconfint_mean(alpha=0.05)\n",
    "        lower_bound.append(low)\n",
    "        upper_bound.append(up)\n",
    "        matrix_array = np.array(matrix_at_d)\n",
    "        averaged_matrix = np.mean(matrix_array, axis=0)\n",
    "        matrix_list.append(averaged_matrix)\n",
    "\n",
    "    # return mean, lower_bound, upper_bound, matrix_list\n",
    "        \n",
    "    data = {'mean': mean, 'lower': lower_bound, 'upper': upper_bound}\n",
    "    df = pd.DataFrame(data, index=xx)\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_singular_value_panel(axes:Axes, df:pd.DataFrame, title:str=\"\"):\n",
    "\n",
    "    xx = df.index\n",
    "\n",
    "    axes.plot(xx, df[\"mean\"], color='dodgerblue', label='Minimum singular value')\n",
    "    axes.fill_between(xx, np.array(df[\"lower\"].values), np.array(df[\"upper\"].values), color='dodgerblue', alpha=0.3)\n",
    "    axes.set_xlabel(\"Cross price elasticity ($\\\\beta^{P1}$)\")\n",
    "    axes.set_ylabel(\"Min. abs. Singular Value\")\n",
    "    axes.set_ylim(0, 40000)\n",
    "    axes.set_xlim(-200, 200)\n",
    "    axes.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_singular_values_results(sample:int=8760*5, linspace:int=100, runs:int=50, model:StructuralModel=StructuralModel.Model_III, estimator:ModelInputParams=ModelInputParams(IVOptions.NUISANCE_ORDER, 1), instruments:int=2, metric:Literal['singular values', 'eigenvalues']=\"singular values\"):\n",
    "    name_dict = {\n",
    "        StructuralModel.Model_I:\"simple_model\",\n",
    "        StructuralModel.Model_II:\"autocorrelated_error\",\n",
    "        StructuralModel.Model_III:\"cross_price\",\n",
    "        StructuralModel.Model_IV:\"complex_model\",\n",
    "    }\n",
    "    _model = name_dict[model]\n",
    "    \n",
    "    file_name = f\"{metric.replace(' ', '_')}_{_model}_{estimator.strategy}_{sample//8760}_years_{runs}_runs_{linspace}_linspace_{instruments}_instruments\".replace(\"IVOptions.\", \"\")\n",
    "\n",
    "    try:\n",
    "        df = read_results_from_file(file_name+'.csv', 1)\n",
    "    except FileNotFoundError as e:\n",
    "        print(e)\n",
    "        df = run_singular_values_analysis(sample=sample, runs=runs, linspace=linspace, estimator=estimator, model=model, instruments=instruments, metric=metric)\n",
    "        write_results_to_file(file_name, df)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def singular_values_plot(sample:int=8760*5, linspace:int=100, runs:int=50, model:StructuralModel=StructuralModel.Model_III, estimator:ModelInputParams=ModelInputParams(IVOptions.NUISANCE_ORDER, 1), instruments:int=2, metric:Literal['singular values', 'eigenvalues']=\"singular values\"):\n",
    "    \n",
    "    name_dict = {\n",
    "        StructuralModel.Model_I:\"simple_model\",\n",
    "        StructuralModel.Model_II:\"autocorrelated_error\",\n",
    "        StructuralModel.Model_III:\"cross_price\",\n",
    "        StructuralModel.Model_IV:\"complex_model\",\n",
    "    }\n",
    "    _model = name_dict[model]\n",
    "    file_name = f\"{metric.replace(' ', '_')}_{_model}_{estimator.strategy}_{sample//8760}_years_{runs}_runs_{linspace}_linspace_{instruments}_instruments\".replace(\"IVOptions.\", \"\")\n",
    "    \n",
    "    df = get_singular_values_results(sample=sample, \n",
    "                                        linspace=linspace, \n",
    "                                        runs=runs, \n",
    "                                        model=model, \n",
    "                                        instruments=instruments,\n",
    "                                        metric=metric)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 1, sharex=True, sharey=True, figsize=(REGULAR_WIDTH, HEIGHT))\n",
    "    plot_singular_value_panel(axes, df, title=\"Singular values of the cross-correlation matrix\\nfor 2 instruments ($W_0, W_1$) and 2 endogeneous variables ($P_0, D_1$)\")\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    save_figure(fig, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# singular_values_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(1, 2, sharex=True, sharey=True, figsize=(6*2, 3.6))\n",
    "# plot_singular_value_panel(axes[0], get_singular_values_results(), title=\"With 2 instruments ($W_t, W_{t-1}$)\")\n",
    "# plot_singular_value_panel(axes[1], get_singular_values_results(instruments=27), title=\"With 27 instruments ($W_t, ..., W_{t-26}$)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
